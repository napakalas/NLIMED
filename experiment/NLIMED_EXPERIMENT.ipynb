{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLIMED import NLIMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('DataTest.json', 'r') as fp:\n",
    "    dataTest = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford server has been started\n"
     ]
    }
   ],
   "source": [
    "\"\"\"NLIMED - PMR - Stanford Parser\"\"\"\n",
    "nlimed = NLIMED(repo='pmr', parser='stanford', pl=2, alpha=0.4, beta=0.1, gamma=1.0, delta=1.0)\n",
    "query = 'flux of sodium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'phrases': ['flux', 'sodium'], 'result': [[['http://identifiers.org/opb/OPB_00593', 'http://purl.obolibrary.org/obo/CHEBI_29101'], 1.4553906641369228], [['https://identifiers.org/opb/OPB_00593', 'http://purl.obolibrary.org/obo/CHEBI_29101'], 1.4537913504562157], [['http://identifiers.org/opb/OPB_00593', 'http://identifiers.org/chebi/CHEBI:29101'], 1.4539927349265542], [['https://identifiers.org/opb/OPB_00593', 'http://identifiers.org/chebi/CHEBI:29101'], 1.4523934212458471]]}\n"
     ]
    }
   ],
   "source": [
    "annotation = nlimed.getAnnotated(query=query,format='json')\n",
    "print(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford server has been started\n",
      "{'phrases': ['flux', 'sodium'], 'result': [[['http://identifiers.org/opb/OPB_00593', 'http://purl.obolibrary.org/obo/CHEBI_29101'], 1.4553906641369228], [['https://identifiers.org/opb/OPB_00593', 'http://purl.obolibrary.org/obo/CHEBI_29101'], 1.4537913504562157], [['http://identifiers.org/opb/OPB_00593', 'http://identifiers.org/chebi/CHEBI:29101'], 1.4539927349265542], [['https://identifiers.org/opb/OPB_00593', 'http://identifiers.org/chebi/CHEBI:29101'], 1.4523934212458471]]}\n"
     ]
    }
   ],
   "source": [
    "sparql = nlimed.getSparql(query=query,format='json')\n",
    "print(sparql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = nlimed.getModels(query=query,format='json')\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     7,
     20,
     29,
     96
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"EXERIMENT'S FUNCTIONS\"\"\"\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "def timeMeasurement(rigid, repeat, **vargs):\n",
    "    print('EXPERIMENT: EXECUTION TIME')\n",
    "    print('Approach \\t time rate (%d)'%repeat)\n",
    "    for annType, annotator in vargs.items():\n",
    "        startTime = time.time()\n",
    "        for i in range(repeat):\n",
    "            for key, data in dataTest.items():\n",
    "                ann = annotator.annotate(data['query'])\n",
    "        endTime = time.time()\n",
    "        print('%s \\t %f second'%(annType,(endTime-startTime)/repeat))\n",
    "    print('\\n')\n",
    "        \n",
    "import re\n",
    "def getURICode(uris):\n",
    "    newUris = []\n",
    "    for uri in uris:\n",
    "        partUri = uri[uri.rfind('/')+1:].lower()\n",
    "        regex = re.compile('[^a-z0-9]')\n",
    "        partUri = regex.sub('', partUri)\n",
    "        newUris += [partUri]\n",
    "    return newUris\n",
    "    \n",
    "def compareAnnotator(rigid, **vargs):\n",
    "    statQueryLen = {}\n",
    "    statGeneral = {}\n",
    "    statPhraseNum = {}\n",
    "    for annType in vargs:\n",
    "        statQueryLen[annType] = {}\n",
    "        statGeneral[annType] = {}\n",
    "        statPhraseNum[annType] = {}\n",
    "        \n",
    "    for key, data in dataTest.items():\n",
    "        data['numPhrase'] = len(data['phrase'])\n",
    "        data['wordLength'] = len(data['query'].translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).lower().split())\n",
    "        correctResult = data['annotation'] if rigid else getURICode(data['annotation'])\n",
    "        for annType, annotator in vargs.items():\n",
    "            \"\"\"collect per query statistic\"\"\"\n",
    "            ann = annotator.getAnnotated(query=data['query'],format='json')\n",
    "            predictResult = ann['result'][0][0] if rigid else getURICode(ann['result'][0][0])\n",
    "            annCorrect = 0\n",
    "            for cResult in correctResult:\n",
    "                annCorrect +=  1 if cResult in predictResult else 0\n",
    "            lenRet = len(predictResult)\n",
    "            data[annType] = {'phrase':ann['phrases'],'numPhrase':len(ann['phrases']),'annotation':ann['result'][0][0],'correct':annCorrect,'false':lenRet-annCorrect}\n",
    "            \"\"\"collect element and query level statistic\"\"\"\n",
    "            shouldRetrieved = data['numPhrase']\n",
    "            retrievedNum = len(ann['phrases'])\n",
    "            correct = annCorrect\n",
    "            false = lenRet-annCorrect\n",
    "            queryCorrect = 1 if data['numPhrase'] == len(ann['phrases']) and annCorrect == len(ann['phrases']) else 0\n",
    "            queryFalse = 0 if queryCorrect == 1 else 1\n",
    "            \"\"\"collect num of words based statistic\"\"\"\n",
    "            wordLength = data['wordLength']\n",
    "            if wordLength in statQueryLen[annType]:\n",
    "                shouldRetrieved_r = statQueryLen[annType][wordLength]['shouldRetrieved']+shouldRetrieved\n",
    "                retrievedNum_r = statQueryLen[annType][wordLength]['retrievedNum']+retrievedNum\n",
    "                correct_r = statQueryLen[annType][wordLength]['correct']+correct\n",
    "                false_r = statQueryLen[annType][wordLength]['false']+false\n",
    "                queryCorrect_r = statQueryLen[annType][wordLength]['queryCorrect']+queryCorrect\n",
    "                queryFalse_r = statQueryLen[annType][wordLength]['queryFalse']+queryFalse\n",
    "                statQueryLen[annType][wordLength] = {'shouldRetrieved':shouldRetrieved_r,'retrievedNum':retrievedNum_r,'correct':correct_r,'false':false_r,'queryCorrect':queryCorrect_r,'queryFalse':queryFalse_r}\n",
    "            else :\n",
    "                statQueryLen[annType][wordLength] = {'shouldRetrieved':shouldRetrieved,'retrievedNum':retrievedNum,'correct':correct,'false':false,'queryCorrect':queryCorrect,'queryFalse':queryFalse}\n",
    "            \"\"\"collect num of phrases based statistic\"\"\"\n",
    "            phraseNum = data['numPhrase']\n",
    "            if phraseNum in statPhraseNum[annType]:\n",
    "                shouldRetrieved_r = statPhraseNum[annType][phraseNum]['shouldRetrieved']+shouldRetrieved\n",
    "                retrievedNum_r = statPhraseNum[annType][phraseNum]['retrievedNum']+retrievedNum\n",
    "                correct_r = statPhraseNum[annType][phraseNum]['correct']+correct\n",
    "                false_r = statPhraseNum[annType][phraseNum]['false']+false\n",
    "                queryCorrect_r = statPhraseNum[annType][phraseNum]['queryCorrect']+queryCorrect\n",
    "                queryFalse_r = statPhraseNum[annType][phraseNum]['queryFalse']+queryFalse\n",
    "                statPhraseNum[annType][phraseNum] = {'shouldRetrieved':shouldRetrieved_r,'retrievedNum':retrievedNum_r,'correct':correct_r,'false':false_r,'queryCorrect':queryCorrect_r,'queryFalse':queryFalse_r}\n",
    "            else :\n",
    "                statPhraseNum[annType][phraseNum] = {'shouldRetrieved':shouldRetrieved,'retrievedNum':retrievedNum,'correct':correct,'false':false,'queryCorrect':queryCorrect,'queryFalse':queryFalse}\n",
    "            \"\"\"collect general statistic\"\"\"\n",
    "            if len(statGeneral[annType]) > 0:\n",
    "                shouldRetrieved_r = statGeneral[annType]['shouldRetrieved']+shouldRetrieved\n",
    "                retrievedNum_r = statGeneral[annType]['retrievedNum']+retrievedNum\n",
    "                correct_r = statGeneral[annType]['correct']+correct\n",
    "                false_r = statGeneral[annType]['false']+false\n",
    "                queryCorrect_r = statGeneral[annType]['queryCorrect']+queryCorrect\n",
    "                queryFalse_r = statGeneral[annType]['queryFalse']+queryFalse\n",
    "                statGeneral[annType] = {'shouldRetrieved':shouldRetrieved_r,'retrievedNum':retrievedNum_r,'correct':correct_r,'false':false_r,'queryCorrect':queryCorrect_r,'queryFalse':queryFalse_r}\n",
    "            else:\n",
    "                statGeneral[annType] = {'shouldRetrieved':shouldRetrieved,'retrievedNum':retrievedNum,'correct':correct,'false':false,'queryCorrect':queryCorrect,'queryFalse':queryFalse}\n",
    "    returnData = {'statGeneral':statGeneral,'statQueryLen':statQueryLen,'statPhraseNum':statPhraseNum,'detilData':dataTest}\n",
    "    return returnData\n",
    "\n",
    "def drawPlot(showData,xlabel):\n",
    "    linestyles = ['--', ':', '-.', '-']\n",
    "    pattern=0\n",
    "    for label, stat in showData.items():\n",
    "        pairData = []\n",
    "        for numOfWord, val in stat.items():\n",
    "            precision = val['correct']/val['retrievedNum']\n",
    "            recall = val['correct']/val['shouldRetrieved']\n",
    "            fmeasure = 2*precision*recall/(precision+recall) if (precision+recall)>0 else 0\n",
    "            pairData += [(numOfWord,fmeasure)]\n",
    "        pairData.sort(key=lambda tup: tup[0])\n",
    "        label = label+' parser' if label != 'NCBO' else 'NCBO Annotator'\n",
    "        plt.plot(*zip(*pairData),linestyles[pattern],label=label,linewidth=1.5)\n",
    "        pattern += 1\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('F-Measure')\n",
    "    plt.legend()\n",
    "    plt.savefig(xlabel+'.pdf',dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "def getGeneralResult(result):\n",
    "    showData = result['statGeneral']\n",
    "    summary = {}\n",
    "    for key, stat in showData.items():\n",
    "        precision = stat['correct'] / stat['retrievedNum']\n",
    "        recall = stat['correct'] / stat['shouldRetrieved']\n",
    "        fmeasure = 2 * precision * recall / (precision + recall)\n",
    "        qAccuracy = stat['queryCorrect'] / (stat['queryCorrect']+stat['queryFalse'])\n",
    "        summary[key] = {'precision':precision, 'recall':recall, 'fmeasure':fmeasure, 'qAccuracy':qAccuracy}\n",
    "    return summary\n",
    "        \n",
    "def printGeneralResult(result, **kwargs):\n",
    "    \"\"\"show general result at element level\"\"\"\n",
    "    print('Performance of all approaches at element level')\n",
    "    print('Approach \\t Precision \\t Recall \\t F-Measure \\t Query accuracy')\n",
    "    summary = getGeneralResult(result)\n",
    "    for key, summ in summary.items():\n",
    "        print('%s \\t %f \\t %f \\t %f \\t %f'%(key, summ['precision'], summ['recall'], summ['fmeasure'], summ['qAccuracy']))    \n",
    "    \n",
    "    \"\"\"print and save plot\"\"\"\n",
    "    if 'plot' in kwargs:\n",
    "        if kwargs['plot'] == True:\n",
    "            \"\"\"show general result at query level\"\"\"\n",
    "            print('Performance of all approaches based on query length')\n",
    "            drawPlot(result['statQueryLen'],'number of terms per query')\n",
    "\n",
    "            print('Performance of all approaches based on num of phrases per query')\n",
    "            drawPlot(result['statPhraseNum'],'number of phrases per query')\n",
    "    \n",
    "    \"\"\"save to file\"\"\"\n",
    "    if 'save' in kwargs:\n",
    "        if kwargs['save'] == True:\n",
    "            with open('result_annotation.json', 'w') as fp:\n",
    "                json.dump(result, fp)\n",
    "                \n",
    "def print4DPlot(config):\n",
    "    def printPlot(parser):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlabel('\\N{greek small letter beta}:'+' synonym')\n",
    "        ax.set_ylabel('\\N{greek small letter gamma}:'+' definition')\n",
    "        ax.set_zlabel('\\N{greek small letter delta}:'+' description')\n",
    "        cm = plt.cm.get_cmap('Spectral')\n",
    "        cm.name = 'F-measure'\n",
    "        img = ax.scatter(config['synonym'], config['definition'], config['description'], c=config[parser], cmap=cm)\n",
    "        fig.colorbar(img)\n",
    "        plt.savefig('multiplierSetup'+parser+'.pdf',dpi=400)\n",
    "        plt.show()\n",
    "    # print for stanford\n",
    "    printPlot('stanford')\n",
    "    # print for nltk\n",
    "    printPlot('nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"ANNOTATION EXPERIMENTS\"\"\"\n",
    "\"\"\"BEST MULTIPLIER\"\"\"\n",
    "\n",
    "print('PrefDef \\t Synonym \\t Definition \\t Mentioned \\t STANFORD \\t NLTK')\n",
    "config = {'prefDef':[],'synonym':[],'definition':[],'description':[],'stanford':[],'nltk':[]}\n",
    "precision = 0.1\n",
    "maxRange = 11\n",
    "maxFMeasure = {'stanford':{'value':0,'combination':[]},'nltk':{'value':0,'combination':[]}}\n",
    "for m_prefDef in range(1,maxRange):\n",
    "    print(\"current preffered def is %d\"%m_prefDef)\n",
    "    for syn in range(maxRange):\n",
    "        m_synonym = round(syn * precision,1)\n",
    "        for define in range(maxRange):\n",
    "            m_definition = round(define * precision,1)\n",
    "            for mention in range(maxRange):\n",
    "                m_mention = round(mention * precision * 3,1)\n",
    "                annoSt = NLIMED(repo='pmr', parser='stanford', pl=1, alpha=m_prefDef, beta=m_synonym, gamma=m_definition, delta=m_mention)\n",
    "                annoNLTK = NLIMED(repo='pmr', parser='nltk', pl=1, alpha=m_prefDef, beta=m_synonym, gamma=m_definition, delta=m_mention)\n",
    "                result = compareAnnotator(False,STANFORD=annoSt,NLTK=annoNLTK)\n",
    "                summary = getGeneralResult(result)\n",
    "                config['prefDef'] += [m_prefDef]\n",
    "                config['synonym'] += [m_synonym]\n",
    "                config['definition'] += [m_definition]\n",
    "                config['description'] += [m_mention]\n",
    "                config['stanford'] += [summary['STANFORD']['fmeasure']]\n",
    "                config['nltk'] += [summary['NLTK']['fmeasure']]\n",
    "                if summary['STANFORD']['fmeasure'] > maxFMeasure['stanford']['value']:\n",
    "                    maxFMeasure['stanford']['value'] = summary['STANFORD']['fmeasure']\n",
    "                    maxFMeasure['stanford']['combination'] = [(m_prefDef,m_synonym,m_definition,m_mention)]\n",
    "                elif summary['STANFORD']['fmeasure'] == maxFMeasure['stanford']['value']:\n",
    "                    maxFMeasure['stanford']['combination'] += [(m_prefDef,m_synonym,m_definition,m_mention)]\n",
    "                if summary['NLTK']['fmeasure'] > maxFMeasure['nltk']['value']:\n",
    "                    maxFMeasure['nltk']['value'] = summary['NLTK']['fmeasure']\n",
    "                    maxFMeasure['nltk']['combination'] = [(m_prefDef,m_synonym,m_definition,m_mention)]\n",
    "                elif summary['NLTK']['fmeasure'] == maxFMeasure['nltk']['value']:\n",
    "                    maxFMeasure['nltk']['combination'] += [(m_prefDef,m_synonym,m_definition,m_mention)]\n",
    "    print(\"finish preffered def %d\"%m_prefDef)\n",
    "    \n",
    "print4DPlot(config)\n",
    "with open('maxFMeasureSetup.json', 'w') as fp:\n",
    "    json.dump(maxFMeasure, fp)\n",
    "with open('configSetup.json', 'w') as fp:\n",
    "    json.dump(config, fp)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"ANNOTATION EXPERIMENTS\"\"\"\n",
    "\"\"\"MULTIPLIER EFFECT\"\"\"\n",
    "print('PrefDef \\t Synonym \\t Definition \\t Mentioned \\t STANFORD \\t NLTK')\n",
    "for alpha in range(1,11):\n",
    "    for other1 in range(11):\n",
    "        oth = other1 * 0.1\n",
    "        annoSt = NLIMED(repo='pmr', parser='stanford', pl=1, alpha=alpha, beta=oth, gamma=0, delta=0)\n",
    "        annoNLTK = NLIMED(repo='pmr', parser='nltk', pl=1, alpha=alpha, beta=oth, gamma=0, delta=0)\n",
    "        result = compareAnnotator(False,STANFORD=annoSt,NLTK=annoNLTK)\n",
    "        summary = getGeneralResult(result)\n",
    "        print('%d \\t%f \\t%f \\t%f \\t%f \\t%f'%(m_prefDef,oth,0,0,summary['STANFORD']['fmeasure'],summary['NLTK']['fmeasure']))\n",
    "        \n",
    "        annoSt = NLIMED(repo='pmr', parser='stanford', pl=1, alpha=alpha, beta=0, gamma=oth, delta=0)\n",
    "        annoNLTK = NLIMED(repo='pmr', parser='nltk', pl=1, alpha=alpha, beta=0, gamma=oth, delta=0)\n",
    "        result = compareAnnotator(False,STANFORD=annoSt,NLTK=annoNLTK)\n",
    "        summary = getGeneralResult(result)\n",
    "        print('%d \\t%f \\t%f \\t%f \\t%f \\t%f'%(m_prefDef,0,oth,0,summary['STANFORD']['fmeasure'],summary['NLTK']['fmeasure']))\n",
    "        \n",
    "        annoSt = NLIMED(repo='pmr', parser='stanford', pl=1, alpha=alpha, beta=0, gamma=0, delta=oth)\n",
    "        annoNLTK = NLIMED(repo='pmr', parser='nltk', pl=1, alpha=alpha, beta=0, gamma=0, delta=oth)\n",
    "        result = compareAnnotator(False,STANFORD=annoSt,NLTK=annoNLTK)\n",
    "        summary = getGeneralResult(result)\n",
    "        print('%d \\t%f \\t%f \\t%f \\t%f \\t%f'%(m_prefDef,0,0,oth,summary['STANFORD']['fmeasure'],summary['NLTK']['fmeasure']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ANNOTATION EXPERIMENTS\"\"\"\n",
    "\"\"\"COMPARE PARSER\"\"\"\n",
    "annoSt = NLIMED(repo='pmr', parser='stanford', pl=1, alpha=0.4, beta=0.1, gamma=1.0, delta=1.0)\n",
    "annoNLTK = NLIMED(repo='pmr', parser='nltk', pl=1, alpha=1.0, beta=0.7, gamma=0.0, delta=0.7)\n",
    "annoNCBO = NLIMED(repo='pmr', parser='ncbo', pl=1)\n",
    "result = compareAnnotator(False,STANFORD=annoSt,NLTK=annoNLTK,NCBO=annoNCBO)\n",
    "summary = getGeneralResult(result)\n",
    "printGeneralResult(result, plot=True, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
